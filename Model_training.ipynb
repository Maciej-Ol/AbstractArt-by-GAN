{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zaimportowanie wymaganych bibliotek\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from keras.layers import Input, Reshape, Dropout, Dense, Flatten, BatchNormalization, Activation, ZeroPadding2D, LeakyReLU, Conv2DTranspose\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.metrics import Mean\n",
    "from numpy import zeros,ones,vstack\n",
    "from numpy.random import randn,randint,normal\n",
    "from numpy.random import default_rng\n",
    "from IPython.display import clear_output\n",
    "from math import trunc\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametry\n",
    "VERSION=0.3\n",
    "#PATH_TO_DATA='data/cubism_data_norm.npy'\n",
    "#DATA=\"cubism\"\n",
    "PATH_TO_DATA='data/delaunay_data_norm.npy'\n",
    "DATA=\"delaunay\"\n",
    "\n",
    "#Number of saved images during training\n",
    "OUTPUT = 8\n",
    "OUTPUT_MARGIN = 4\n",
    "SAVE_FREQ = 100 #How often to save images\n",
    "OUTPUT_PATH='output\\\\new'\n",
    "'''\n",
    "In this use case, our latent space representations are used to\n",
    "transform more complex forms of raw data (i.e. images, video),\n",
    "into simpler representations which are \"more convenient to process\" and analyze.\n",
    "'''\n",
    "NOISE_SIZE = 128#Lantent dimention size\n",
    "\n",
    "EPOCHS = 5000 #Iterations 100000 the biger, the longer the model will train\n",
    "BATCH_SIZE = 64 #number of images in the Batch. Larger Batch → Weak Generalization, Larger Batches → Fewer updates + shifting data → lower computational costs\n",
    "\n",
    "#\n",
    "#cross_entropy=BinaryCrossentropy()\n",
    "mean=Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(number of images,size_x,size_y,color_channels)\n",
      "(11503, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(PATH_TO_DATA)\n",
    "print(\"(number of images,size_x,size_y,color_channels)\")\n",
    "print(train_data.shape)\n",
    "if train_data.shape[1]!=train_data.shape[2]:\n",
    "    print(\"Something is wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of images\n",
    "IMG_SIZE = train_data.shape[1] #rows/cols\n",
    "IMG_CHANNELS = train_data.shape[3] #color channels in our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(((train_data[1]+1)*255/2).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator\n",
    "def build_discriminator(image_shape):\n",
    "    model = Sequential(name=\"Discriminator\")\n",
    "        \n",
    "    #model.add(Conv2D(32, kernel_size=4, strides=2,input_shape=image_shape,data_format=\"channels_last\",padding=\"same\"))\n",
    "    #model.add(BatchNormalization(axis=1,momentum=0.8))\n",
    "    #model.add(LeakyReLU(alpha=0.2))\n",
    "    #model.add(Dropout(0.25))#dropout layer to prevent overfitting    \n",
    "    \n",
    "    model.add(Conv2D (64, kernel_size=4, strides=2, padding=\"same\",input_shape=image_shape,data_format=\"channels_last\"))\n",
    "    #model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.20))    \n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.20))    \n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))    \n",
    "    model.add(Dropout(0.20))\n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=4, strides=1, padding=\"valid\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))    \n",
    "    model.add(Dropout(0.20))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))#binary clasification\n",
    "\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=binary_crossentropy,optimizer=opt,metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator\n",
    "def build_generator(noise_size, channels):\n",
    "     model = Sequential(name=\"Generator\")\n",
    "     model.add(Dense(1 * 1 * 128, activation=\"relu\",input_dim=noise_size))\n",
    "     model.add(Reshape((1, 1, 128)))    \n",
    "     model.add(Conv2DTranspose(512,kernel_size=4, strides=1, padding=\"valid\"))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))    \n",
    "               \n",
    "     #model.add(UpSampling2D())\n",
    "     #model.add(Conv2D(256, kernel_size=4, padding=\"same\"))\n",
    "     model.add(Conv2DTranspose(256,kernel_size=4, strides=2, padding=\"same\"))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))    \n",
    "\n",
    "     #model.add(UpSampling2D())\n",
    "     #model.add(Conv2D(256, kernel_size=4, padding=\"same\"))\n",
    "     model.add(Conv2DTranspose(128,kernel_size=4, strides=2, padding=\"same\"))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))\n",
    "     \n",
    "     model.add(Conv2DTranspose(64,kernel_size=4, strides=2, padding=\"same\"))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))        \n",
    "          \n",
    "     model.add(Conv2DTranspose(channels, kernel_size=4,strides=2, padding=\"same\"))\n",
    "     model.add(Activation(\"tanh\"))    \n",
    "\n",
    "     model.summary()\n",
    "\n",
    "     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential(name=\"GAN\")\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(generator,noise,number):\n",
    "    generated_images = generator.predict(noise)\n",
    "    print(generated_images)\n",
    "    #from (-1,1) to (0,255)\n",
    "    generated_images = (generated_images+1)*255/2\n",
    "    if not os.path.exists(OUTPUT_PATH):\n",
    "        os.makedirs(OUTPUT_PATH)\n",
    "    filename = os.path.join(OUTPUT_PATH, DATA+\"-%d.png\"%(number))\n",
    "    im = Image.fromarray(generated_images)\n",
    "    im.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_samples(data, n_samples):\n",
    "    indexes = randint(0, data.shape[0], n_samples)\n",
    "    X = data[indexes]\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    x_input = default_rng().normal(0.0, 1.0, (n_samples, latent_dim))\n",
    "    X = generator.predict(x_input)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, generator, discriminator, dataset, latent_dim, n_samples=100):\n",
    "    #getting samples and evaluating\n",
    "    X_real, y_real = get_real_samples(dataset, n_samples)\n",
    "    _, acc_real = discriminator.evaluate(X_real, y_real, verbose=0)\n",
    "    x_fake, y_fake = generate_fake_samples(generator, latent_dim, n_samples)\n",
    "    _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
    "    print('Accuracy on real: %.0f%%, on fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "    filename = 'gen_model_v_%.1f_e_%d.h5' % (VERSION,epoch + 1)\n",
    "    generator.save('models\\\\'+filename,include_optimizer=True)\n",
    "    return acc_real,acc_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, gan_model, dataset, latent_dim, n_epochs=100, n_batch=10):\n",
    "    batchs_per_epoch = int(dataset.shape[0] / n_batch)\n",
    "    half_of_batch=int(int(n_batch / 2))\n",
    "    #generating fixed noise for examples images\n",
    "    fixed_noise = default_rng().normal(loc=0.0, scale=1.0, size=(OUTPUT * OUTPUT, latent_dim))\n",
    "    number=1\n",
    "    perfect_rounds=0\n",
    "    i=0\n",
    "    work=True\n",
    "    while i <= n_epochs and work:\n",
    "        for j in range(batchs_per_epoch):\n",
    "            #geting and generating samples\n",
    "            X_real, y_real = get_real_samples(dataset, half_of_batch)\n",
    "            X_fake, y_fake = generate_fake_samples(generator, latent_dim, half_of_batch)\n",
    "            #joining the real images with false ones\n",
    "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "            X_gan = default_rng().normal(0.0, 1.0, (n_batch,latent_dim))\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            #training\n",
    "            d_loss,_ = discriminator.train_on_batch(X, y)\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            print('Epoch:%d, Batch:%d/%d, d_loss=%.4f, g_loss=%.4f' % (i+1, j+1, batchs_per_epoch, d_loss, g_loss))\n",
    "        if (i+1) % 10 == 0:\n",
    "            #saving images based on fixed noise\n",
    "            save_images(generator, fixed_noise, number)\n",
    "            number+=1\n",
    "            clear_output()\n",
    "            #getting accuracy\n",
    "            acc_real,acc_fake=summarize_performance(i, generator, discriminator, dataset, latent_dim)\n",
    "            #if both accuraccies is 100% for 5 epochs, than end program\n",
    "            if round(acc_real,2)==100.00 and round(acc_fake,2)==100.00:\n",
    "                perfect_rounds+=1\n",
    "            else:\n",
    "                perfect_rounds=0\n",
    "            if(perfect_rounds==5):\n",
    "                work=False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        3136      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131200    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 256)         524544    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 5, 256)         1048832   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 5, 5, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 5, 5, 256)         0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 5, 5, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 6401      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,716,929\n",
      "Trainable params: 1,715,521\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Model: \"Generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 4, 4, 512)        1049088   \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 8, 8, 256)        2097408   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 16, 16, 128)      524416    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 32, 32, 64)       131136    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 64, 64, 3)        3075      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,825,475\n",
      "Trainable params: 3,823,555\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "Model: \"GAN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Generator (Sequential)      (None, 64, 64, 3)         3825475   \n",
      "                                                                 \n",
      " Discriminator (Sequential)  (None, 1)                 1716929   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,542,404\n",
      "Trainable params: 3,823,555\n",
      "Non-trainable params: 1,718,849\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "Epoch:1, Batch:1/1150, d_loss=0.7757, g_loss=0.7034\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:2/1150, d_loss=0.2480, g_loss=0.7007\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:3/1150, d_loss=0.0956, g_loss=0.7391\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:4/1150, d_loss=0.0523, g_loss=0.6489\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:5/1150, d_loss=0.0374, g_loss=0.4943\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:6/1150, d_loss=0.0249, g_loss=0.3295\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:7/1150, d_loss=0.1427, g_loss=0.1703\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch:1, Batch:8/1150, d_loss=0.0488, g_loss=0.0625\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:9/1150, d_loss=0.0478, g_loss=0.0297\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:10/1150, d_loss=0.2524, g_loss=0.0095\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:11/1150, d_loss=0.1729, g_loss=0.0394\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:12/1150, d_loss=0.1388, g_loss=0.1018\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:13/1150, d_loss=0.0155, g_loss=0.1522\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:14/1150, d_loss=0.5807, g_loss=0.4378\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:15/1150, d_loss=0.0732, g_loss=0.2223\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:16/1150, d_loss=1.7375, g_loss=4.5651\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:17/1150, d_loss=0.0054, g_loss=3.9489\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:18/1150, d_loss=0.3947, g_loss=1.6062\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:19/1150, d_loss=3.0453, g_loss=5.1032\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:20/1150, d_loss=0.7023, g_loss=10.5592\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch:1, Batch:21/1150, d_loss=0.4104, g_loss=10.4646\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:22/1150, d_loss=0.1572, g_loss=7.7067\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:23/1150, d_loss=0.3348, g_loss=5.5923\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:24/1150, d_loss=1.1458, g_loss=8.8773\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:25/1150, d_loss=0.3499, g_loss=9.0464\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:26/1150, d_loss=0.3289, g_loss=8.2473\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch:1, Batch:27/1150, d_loss=0.8390, g_loss=7.9252\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:28/1150, d_loss=2.1649, g_loss=10.9196\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:29/1150, d_loss=0.3043, g_loss=7.5156\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:30/1150, d_loss=0.2617, g_loss=2.3196\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:31/1150, d_loss=2.2250, g_loss=2.1852\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:32/1150, d_loss=1.3165, g_loss=4.0268\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:33/1150, d_loss=0.7243, g_loss=2.6909\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:34/1150, d_loss=0.2394, g_loss=0.9264\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:35/1150, d_loss=0.7316, g_loss=0.6635\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:36/1150, d_loss=0.1153, g_loss=0.3678\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:37/1150, d_loss=0.0863, g_loss=0.2546\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:38/1150, d_loss=0.0668, g_loss=0.5185\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:39/1150, d_loss=0.0193, g_loss=0.3120\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:40/1150, d_loss=0.0786, g_loss=0.2497\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:41/1150, d_loss=0.2283, g_loss=0.7783\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:42/1150, d_loss=0.0865, g_loss=0.8935\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch:1, Batch:43/1150, d_loss=0.0727, g_loss=0.4667\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch:1, Batch:44/1150, d_loss=0.0418, g_loss=0.1527\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:45/1150, d_loss=0.4981, g_loss=0.5100\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:46/1150, d_loss=0.1199, g_loss=0.7574\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Epoch:1, Batch:47/1150, d_loss=1.0827, g_loss=4.3559\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:48/1150, d_loss=0.0289, g_loss=3.3218\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:49/1150, d_loss=0.4565, g_loss=0.9354\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:50/1150, d_loss=1.3423, g_loss=1.9735\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:51/1150, d_loss=0.2657, g_loss=1.6435\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:52/1150, d_loss=0.4182, g_loss=0.7887\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:53/1150, d_loss=0.4047, g_loss=0.7621\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Epoch:1, Batch:54/1150, d_loss=0.1470, g_loss=0.9070\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:55/1150, d_loss=0.3438, g_loss=0.7156\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch:1, Batch:56/1150, d_loss=0.1188, g_loss=0.7800\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:57/1150, d_loss=0.3174, g_loss=1.1633\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Epoch:1, Batch:58/1150, d_loss=0.2461, g_loss=1.3260\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch:1, Batch:59/1150, d_loss=0.1248, g_loss=1.5294\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch:1, Batch:60/1150, d_loss=0.3648, g_loss=2.2348\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:61/1150, d_loss=0.0594, g_loss=2.0650\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:62/1150, d_loss=0.2003, g_loss=1.6962\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Epoch:1, Batch:63/1150, d_loss=0.1074, g_loss=1.6236\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:64/1150, d_loss=0.2519, g_loss=1.8658\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:65/1150, d_loss=0.5666, g_loss=4.9384\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:66/1150, d_loss=0.0291, g_loss=4.8116\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:67/1150, d_loss=0.0541, g_loss=3.7293\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:68/1150, d_loss=0.4225, g_loss=1.7252\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Epoch:1, Batch:69/1150, d_loss=0.4871, g_loss=1.1484\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Epoch:1, Batch:70/1150, d_loss=1.9793, g_loss=5.2418\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch:1, Batch:71/1150, d_loss=0.0762, g_loss=6.3933\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:72/1150, d_loss=0.2162, g_loss=6.2116\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:73/1150, d_loss=0.2996, g_loss=5.3341\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:74/1150, d_loss=0.2473, g_loss=4.2659\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:75/1150, d_loss=0.1232, g_loss=3.5384\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch:1, Batch:76/1150, d_loss=0.0999, g_loss=2.5906\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:77/1150, d_loss=0.3069, g_loss=2.1326\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:78/1150, d_loss=0.4961, g_loss=2.8230\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:79/1150, d_loss=0.0882, g_loss=2.4206\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:80/1150, d_loss=0.0586, g_loss=1.7786\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:81/1150, d_loss=0.4644, g_loss=2.1933\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:82/1150, d_loss=0.1005, g_loss=1.8937\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:83/1150, d_loss=0.7796, g_loss=2.9475\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:84/1150, d_loss=0.1876, g_loss=3.0700\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Epoch:1, Batch:85/1150, d_loss=0.6360, g_loss=3.1830\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch:1, Batch:86/1150, d_loss=0.0711, g_loss=1.9918\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Epoch:1, Batch:87/1150, d_loss=0.6759, g_loss=2.6143\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:88/1150, d_loss=1.3816, g_loss=5.8274\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch:1, Batch:89/1150, d_loss=0.1109, g_loss=6.2244\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:90/1150, d_loss=0.5640, g_loss=4.8460\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Epoch:1, Batch:91/1150, d_loss=0.6246, g_loss=3.1610\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Epoch:1, Batch:92/1150, d_loss=0.1266, g_loss=1.8813\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Epoch:1, Batch:93/1150, d_loss=1.4682, g_loss=2.8719\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:94/1150, d_loss=0.0245, g_loss=2.3556\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:95/1150, d_loss=0.1257, g_loss=1.6674\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:96/1150, d_loss=0.6765, g_loss=1.0271\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch:1, Batch:97/1150, d_loss=0.3174, g_loss=1.6152\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch:1, Batch:98/1150, d_loss=0.2800, g_loss=2.3690\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch:1, Batch:99/1150, d_loss=0.0408, g_loss=1.8558\n"
     ]
    }
   ],
   "source": [
    "image_shape = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n",
    "discriminator = build_discriminator(image_shape)\n",
    "generator = build_generator(NOISE_SIZE, IMG_CHANNELS)\n",
    "\n",
    "gan_model = build_gan(generator, discriminator)\n",
    "#print(train_data.shape)\n",
    "train(generator, discriminator, gan_model, np.array(train_data), NOISE_SIZE,EPOCHS)\n",
    "#print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_model(filename=\"\"):\n",
    "    generator\n",
    "    if(filename!=\"\"):\n",
    "        generator=load_model(\"models\\\\\"+filename,compile=False)\n",
    "    return generator\n",
    "\n",
    "model = get_gen_model()\n",
    "latent_points = default_rng().normal(0.0, 1.0, (NOISE_SIZE, 1))\n",
    "X = model.predict(latent_points)\n",
    "#array = np.array(((0.5*X.reshape(64,64,3)+1)*255).astype(np.uint8))\n",
    "array = np.array(((X.reshape(64,64,3)+1)*255/2).astype(np.uint8))\n",
    "\n",
    "image = Image.fromarray(array)\n",
    "image.show()\n",
    "#image.save(\"output\\\\a1.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93d942669e1cf03727884ffd0f90dfde4a7a65cf123d21da6912f8331dcd819b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
