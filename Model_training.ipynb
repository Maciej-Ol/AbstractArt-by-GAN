{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zaimportowanie wymaganych bibliotek\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from keras.layers import Input, Reshape, Dropout, Dense, Flatten, BatchNormalization, Activation, ZeroPadding2D, LeakyReLU, Conv2DTranspose\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.losses import binary_crossentropy\n",
    "from numpy import zeros,ones,vstack\n",
    "from numpy.random import randn,randint,normal,random,choice\n",
    "from numpy.random import default_rng\n",
    "from IPython.display import clear_output\n",
    "from math import trunc\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters & data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametry\n",
    "VERSION=1.0\n",
    "\n",
    "#can be cub-cubism or del-delaunay\n",
    "DATA=\"cubism\"\n",
    "#DATA=\"delaunay\"\n",
    "#DATA=\"wikiart\"\n",
    "\n",
    "\n",
    "#Number of saved images during training\n",
    "OUTPUT = 5 # grid of output x output images\n",
    "# For now there is no margin between images\n",
    "SAVE_FREQ = 5 #How often to save images and models\n",
    "OVERRIDE_MODEL = False #Option to either save latest model or all of them\n",
    "OUTPUT_PATH='output\\\\new\\\\' # where to save images\n",
    "'''\n",
    "In this use case, our latent space representations are used to\n",
    "transform more complex forms of raw data (i.e. images, video),\n",
    "into simpler representations which are \"more convenient to process\" and analyze.\n",
    "'''\n",
    "NOISE_SIZE = 128#Lantent dimention size\n",
    "\n",
    "EPOCHS = 5000 #Iterations the biger, the longer the model will train\n",
    "BATCH_SIZE = 10 #number of images in the Batch. Larger Batch → Weak Generalization, Larger Batches → Fewer updates + shifting data → lower computational costs\n",
    "\n",
    "#Columns of stats\n",
    "STATS=[[\"Epoch\",\"batch_t\",\"d_loss\",\"g_loss\",\"acc_real\",\"acc_fake\"]]\n",
    "STATS_PATH=\"output\\\\statistics\\\\\" # where to save stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA ==\"delaunay\":\n",
    "    DATASET_NAME=\"del\"\n",
    "    PATH_TO_DATA='data\\\\delaunay_data_norm.npy'\n",
    "elif DATA ==\"cubism\":\n",
    "    DATASET_NAME=\"cub\"\n",
    "    PATH_TO_DATA='data\\\\cubism_data_norm.npy'\n",
    "else:\n",
    "    DATASET_NAME=\"wikiart\"\n",
    "    PATH_TO_DATA='data\\\\wikiart_data_norm.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data load\n",
    "train_data = np.load(PATH_TO_DATA)\n",
    "print(\"(number of images, size_x, size_y, color_channels)\")\n",
    "print(train_data.shape)\n",
    "#checking if the images are square\n",
    "if train_data.shape[1]!=train_data.shape[2]:\n",
    "    print(\"Something is wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of images\n",
    "IMG_SIZE = train_data.shape[1] #rows/cols\n",
    "IMG_CHANNELS = train_data.shape[3] #color channels in our images\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS) #shape of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image example\n",
    "Image.fromarray(((train_data[1]+1)*255/2).astype(np.uint8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator\n",
    "def build_discriminator(image_shape):\n",
    "    model = Sequential(name=\"Discriminator\")\n",
    "    init = RandomNormal(mean=0.0, stddev=0.02)\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=4, strides=2, padding=\"same\",\n",
    "                     input_shape=image_shape, data_format=\"channels_last\", kernel_initializer=init, use_bias=False))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.20))    \n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\", kernel_initializer=init, use_bias=False))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.20))    \n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=4, strides=2, padding=\"same\",kernel_initializer=init, use_bias=False))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))    \n",
    "    model.add(Dropout(0.20))\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=4, strides=2, padding=\"same\",kernel_initializer=init, use_bias=False))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))    \n",
    "    model.add(Dropout(0.20))\n",
    "    \n",
    "    model.add(Conv2D(1024, kernel_size=4, strides=2, padding=\"same\",kernel_initializer=init, use_bias=False))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))    \n",
    "    model.add(Dropout(0.20))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=binary_crossentropy, optimizer=opt, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator\n",
    "def build_generator(noise_size, channels):\n",
    "     model = Sequential(name=\"Generator\")\n",
    "     init = RandomNormal(mean=0.0, stddev=0.02)\n",
    "     model.add(Dense(4 * 4 * 128,input_dim=noise_size,kernel_initializer=init,use_bias=False))\n",
    "     #model.add(Activation(\"relu\"))\n",
    "     model.add(Reshape((4, 4, 128)))\n",
    "     \n",
    "     model.add(Conv2DTranspose(512,kernel_size=4, strides=2, padding=\"same\",kernel_initializer=init,use_bias=False))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))\n",
    "     \n",
    "     model.add(Conv2DTranspose(256,kernel_size=4, strides=2, padding=\"same\", kernel_initializer=init, use_bias=False))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))    \n",
    "\n",
    "     model.add(Conv2DTranspose(128,kernel_size=4, strides=2, padding=\"same\", kernel_initializer=init, use_bias=False))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))\n",
    "     \n",
    "     #model.add(Conv2DTranspose(128,kernel_size=4, strides=2, padding=\"same\", kernel_initializer=init, use_bias=False))\n",
    "     #model.add(BatchNormalization(momentum=0.8))\n",
    "     #model.add(Activation(\"relu\"))\n",
    "     \n",
    "     model.add(Conv2DTranspose(channels, kernel_size=4,strides=2, padding=\"same\", kernel_initializer=init, use_bias=False))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"tanh\"))\n",
    "\n",
    "     model.summary()\n",
    "\n",
    "     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generative adversarial network\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential(name=\"GAN\")\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving examples during training\n",
    "def save_images(epoch,generator, noise):\n",
    "    generated_images = generator.predict(noise)\n",
    "    array=np.empty((IMG_SHAPE),float)\n",
    "    count=0\n",
    "    #creating a grid of images\n",
    "    for i in range(OUTPUT):\n",
    "        for j in range(OUTPUT):\n",
    "            if j==0:\n",
    "                array_pom=np.array(generated_images[count].reshape(64,64,3,order='C'))\n",
    "            else:\n",
    "                array_pom=np.concatenate((array_pom,np.array(\n",
    "                    generated_images[count].reshape(64,64,3,order='C'))),axis=1)\n",
    "            count+=1\n",
    "        if i==0:\n",
    "            array=array_pom\n",
    "        else:\n",
    "            array=np.concatenate((array,array_pom),axis=0)\n",
    "    if not os.path.exists(OUTPUT_PATH):\n",
    "        os.makedirs(OUTPUT_PATH)\n",
    "    filename = os.path.join(OUTPUT_PATH, DATA+\"_v_%.1f_e_%d.png\"%(VERSION,epoch))\n",
    "    #from (-1,1) to (0,255)\n",
    "    im = Image.fromarray(((array+1)*255/2).astype(np.uint8))\n",
    "    im.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting real samples from the data\n",
    "def get_real_samples(data, n_samples):\n",
    "    indexes = randint(0, data.shape[0], n_samples)\n",
    "    X = data[indexes]\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "#generating fake samples using generator\n",
    "def generate_fake_samples(generator, n_samples, noise):\n",
    "    x_input = default_rng().normal(0.0, 1.0, (n_samples, noise))\n",
    "    X = generator.predict(x_input)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "#creating errors in labels \n",
    "def flip_labels(y, proc_to_flip):\n",
    " # determine the number of labels to flip\n",
    " n_select = int(proc_to_flip * y.shape[0])\n",
    " # choose labels to flip\n",
    " flip_ix = choice([i for i in range(y.shape[0])], size=n_select)\n",
    " # invert the labels in place\n",
    " y[flip_ix] = 1 - y[flip_ix]\n",
    " return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graf plotting and model saving\n",
    "def summarize_performance(epoch, stats=STATS):\n",
    "    st=pd.DataFrame(stats[1:], columns=stats[0])\n",
    "    fig, ax = plt.subplots(2, 1)\n",
    "    ax[0].set_title(\"Loss\")#Loss\n",
    "    ax[0].plot(st.g_loss, label='generator')#on fake\n",
    "    ax[0].plot(st.d_loss, label='discriminator')#on real\n",
    "    ax[0].legend()\n",
    "    ax[1].set_title(\"Accuracy\")#Accuracy\n",
    "    ax[1].plot(st.acc_fake, label='generator')#fake\n",
    "    ax[1].plot(st.acc_real, label='discriminator')#real\n",
    "    ax[1].legend()\n",
    "    fig.suptitle(\"Epoch: %d\"%(epoch))\n",
    "    fig.tight_layout()\n",
    "    #plt.savefig((STAT_PATH+\"statistics_plot_v_%.1f.png\" % (VERSION)))\n",
    "    plt.show()\n",
    "    st.to_csv((STATS_PATH+'stats_'+DATASET_NAME+'_%.1f.csv'%(VERSION)))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model\n",
    "def save_generator(epoch, generator, override_model=OVERRIDE_MODEL):\n",
    "    if override_model:\n",
    "        filename = DATASET_NAME+'_model_v_%.1f.h5' % (VERSION)\n",
    "    else:\n",
    "        filename = DATASET_NAME+'_model_v_%.1f_e_%d.h5' % (VERSION,epoch)\n",
    "    generator.save('models\\\\new\\\\'+filename,include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, gan_model, dataset, \n",
    "          noise=NOISE_SIZE, n_epochs=1000, n_batch=10):\n",
    "    batchs_per_epoch = int(dataset.shape[0] / n_batch)\n",
    "    batch_size_r=int(int(n_batch / 2))\n",
    "    #generating fixed noise for images examples\n",
    "    fixed_noise = default_rng().normal(\n",
    "        loc=0.0, scale=1.0, size=(OUTPUT * OUTPUT, noise))\n",
    "    i=0\n",
    "    while i <= n_epochs:\n",
    "        for j in range(batchs_per_epoch):\n",
    "            #geting and generating samples\n",
    "            X_real, y_real = get_real_samples(dataset, batch_size_r)\n",
    "            X_fake, y_fake = generate_fake_samples(\n",
    "                generator, n_batch-batch_size_r,  noise)\n",
    "            X_gan = default_rng().normal(0.0, 1.0, (n_batch, noise))\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            #creating errors in labels\n",
    "            #y_real =flip_labels(y_real, 0.05)\n",
    "            #y_fake =flip_labels(y_fake, 0.05)\n",
    "            #stacking real and false images for traning\n",
    "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "            #training\n",
    "            d_loss, acc_mix = discriminator.train_on_batch(X, y)\n",
    "            _, acc_real = discriminator.evaluate(X_real, y_real, verbose=0)\n",
    "            _, acc_fake = discriminator.evaluate(X_fake, y_fake, verbose=0)\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            STATS.append([i+1,(i)*batchs_per_epoch+(j+1), d_loss, g_loss, acc_real, acc_fake])\n",
    "            print('Epoch:%d, Batch:%d/%d, d_loss=%.4f g_loss=%.4f' %\n",
    "                  (i+1, j+1, batchs_per_epoch, d_loss, g_loss))\n",
    "        if (i+1) % SAVE_FREQ == 0:\n",
    "            #saving images generated from fixed noise\n",
    "            save_images(i+1,generator, fixed_noise)\n",
    "            save_generator(i+1,generator)\n",
    "            clear_output()\n",
    "            summarize_performance(i+1,STATS)\n",
    "            print('Accuracy on real: %.0f%%, on fake: %.0f%%' % \n",
    "                  (acc_real*100, acc_fake*100))\n",
    "            #increase the real batch part in discriminator training\n",
    "            #with each save add 2,5%\n",
    "            if batch_size_r<n_batch:\n",
    "                batch_size_r+=int(int(n_batch / 80))            \n",
    "        i+=1\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the training\n",
    "discriminator = build_discriminator(IMG_SHAPE)\n",
    "generator = build_generator(NOISE_SIZE, IMG_CHANNELS)\n",
    "STATS=[STATS[0]]\n",
    "gan_model = build_gan(generator, discriminator)\n",
    "train(generator, discriminator, gan_model, np.array(train_data), NOISE_SIZE,EPOCHS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "col = STATS[0]\n",
    "df = pd.read_csv(\"output\\\\statistics\\\\stats_cub_0.8.csv\", usecols=col, sep=',',engine='python')\n",
    "#print(\"Contents in csv file:\", df)\n",
    "plt.plot(df.acc_real, label='Dyskryminator')\n",
    "plt.plot(df.acc_fake, label='Generator')\n",
    "plt.title(\"Accuracy during traning\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "col = STATS[0]\n",
    "df = pd.read_csv(\"output\\\\statistics\\\\stats_cub_0.8.csv\", usecols=col,sep=',',engine='python')\n",
    "#print(\"Contents in csv file:\", df)\n",
    "plt.plot(df.g_loss, color='g', label='Generator')\n",
    "plt.plot(df.d_loss, color='b', label='Dyskryminator')\n",
    "plt.title(\"Loss during traning\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating image grid on already trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_model(filename=\"\"):\n",
    "    generator=Sequential()\n",
    "    if(filename!=\"\"):\n",
    "        generator=load_model(\"models\\\\\"+filename,compile=False)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_image_grid(generator, x=1, y=1):\n",
    "    latent_points = default_rng().normal(0.0, 1.0, (x*y, NOISE_SIZE))\n",
    "    X = generator.predict(latent_points)\n",
    "    array=np.empty(((IMG_SHAPE)),float)\n",
    "    count=0\n",
    "    for i in range(y):\n",
    "        for j in range(x):\n",
    "            if j==0:\n",
    "                array_pom=np.array(X[count].reshape(64, 64, 3, order='C'))\n",
    "            else:\n",
    "                array_pom=np.concatenate((\n",
    "                    array_pom,np.array(X[count].reshape(\n",
    "                        64, 64, 3, order='C'))), axis=1)\n",
    "            count+=1\n",
    "        if i==0:\n",
    "            array=array_pom\n",
    "        else:\n",
    "            array=np.concatenate((array, array_pom), axis=0)\n",
    "    array=(array+1)*255/2\n",
    "    return array.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_gen_model(\"examples\\\\cub_model_v_0.8_e_32-.h5\")\n",
    "x=8\n",
    "y=8\n",
    "array = gen_image_grid(model, x, y)\n",
    "image = Image.fromarray((array).astype(np.uint8))\n",
    "image.show()\n",
    "#image.save(\"output\\\\a1.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93d942669e1cf03727884ffd0f90dfde4a7a65cf123d21da6912f8331dcd819b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
