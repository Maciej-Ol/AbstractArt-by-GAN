{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zaimportowanie wymaganych bibliotek\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from keras.layers import Input, Reshape, Dropout, Dense, Flatten, BatchNormalization, Activation, ZeroPadding2D, LeakyReLU, Conv2DTranspose\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from numpy import zeros,ones,vstack\n",
    "from numpy.random import randn,randint,normal\n",
    "from numpy.random import default_rng\n",
    "from IPython.display import clear_output\n",
    "from math import trunc\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametry\n",
    "VERSION=0.7\n",
    "#PATH_TO_DATA='data/cubism_data_norm.npy'\n",
    "#DATA=\"cubism\"\n",
    "PATH_TO_DATA='data/delaunay_data_norm.npy'\n",
    "DATA=\"delaunay\"\n",
    "\n",
    "#Number of saved images during training\n",
    "OUTPUT = 8\n",
    "OUTPUT_MARGIN = 4\n",
    "SAVE_FREQ = 100 #How often to save images\n",
    "OUTPUT_PATH='output\\\\new'\n",
    "'''\n",
    "In this use case, our latent space representations are used to\n",
    "transform more complex forms of raw data (i.e. images, video),\n",
    "into simpler representations which are \"more convenient to process\" and analyze.\n",
    "'''\n",
    "NOISE_SIZE = 128#Lantent dimention size\n",
    "\n",
    "EPOCHS = 5000 #Iterations 100000 the biger, the longer the model will train\n",
    "BATCH_SIZE = 64 #number of images in the Batch. Larger Batch → Weak Generalization, Larger Batches → Fewer updates + shifting data → lower computational costs\n",
    "\n",
    "AVERAGE=[\"Epoch\",\"Accuracy on real\",\"Accuracy on fake\"]\n",
    "LOSS=[\"Epoch\",\"Batch/Batch\",\"Dyskryminator loss\",\"Generator Loss\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(PATH_TO_DATA)\n",
    "print(\"(number of images,size_x,size_y,color_channels)\")\n",
    "print(train_data.shape)\n",
    "if train_data.shape[1]!=train_data.shape[2]:\n",
    "    print(\"Something is wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"cub\"\n",
    "if DATA ==\"delaunay\":\n",
    "    DATASET_NAME=\"del\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of images\n",
    "IMG_SIZE = train_data.shape[1] #rows/cols\n",
    "IMG_CHANNELS = train_data.shape[3] #color channels in our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(((train_data[1]+1)*255/2).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator\n",
    "def build_discriminator(image_shape):\n",
    "    model = Sequential(name=\"Discriminator\")\n",
    "        \n",
    "    #model.add(Conv2D(32, kernel_size=4, strides=2,input_shape=image_shape,data_format=\"channels_last\",padding=\"same\"))\n",
    "    #model.add(BatchNormalization(axis=1,momentum=0.8))\n",
    "    #model.add(LeakyReLU(alpha=0.2))\n",
    "    #model.add(Dropout(0.25))#dropout layer to prevent overfitting    \n",
    "    \n",
    "    model.add(Conv2D (64, kernel_size=4, strides=2, padding=\"same\",input_shape=image_shape,data_format=\"channels_last\"))\n",
    "    #model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.20))    \n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.20))    \n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))    \n",
    "    model.add(Dropout(0.20))\n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=4, strides=1, padding=\"valid\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))    \n",
    "    model.add(Dropout(0.20))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))#binary clasification\n",
    "\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=binary_crossentropy,optimizer=opt,metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator\n",
    "def build_generator(noise_size, channels):\n",
    "     model = Sequential(name=\"Generator\")\n",
    "     model.add(Dense(1 * 1 * 128, activation=\"relu\",input_dim=noise_size))\n",
    "     model.add(Reshape((1, 1, 128)))    \n",
    "     model.add(Conv2DTranspose(512,kernel_size=4, strides=1, padding=\"valid\"))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))    \n",
    "               \n",
    "     #model.add(UpSampling2D())\n",
    "     #model.add(Conv2D(256, kernel_size=4, padding=\"same\"))\n",
    "     model.add(Conv2DTranspose(256,kernel_size=4, strides=2, padding=\"same\"))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))    \n",
    "\n",
    "     #model.add(UpSampling2D())\n",
    "     #model.add(Conv2D(256, kernel_size=4, padding=\"same\"))\n",
    "     model.add(Conv2DTranspose(128,kernel_size=4, strides=2, padding=\"same\"))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))\n",
    "     \n",
    "     model.add(Conv2DTranspose(64,kernel_size=4, strides=2, padding=\"same\"))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))        \n",
    "          \n",
    "     model.add(Conv2DTranspose(channels, kernel_size=4,strides=2, padding=\"same\"))\n",
    "     model.add(Activation(\"tanh\"))    \n",
    "\n",
    "     model.summary()\n",
    "\n",
    "     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential(name=\"GAN\")\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(generator, noise, number):\n",
    "    generated_images = generator.predict(noise)\n",
    "    array=np.empty(((IMG_SIZE,IMG_SIZE,IMG_CHANNELS)),float)\n",
    "\n",
    "    #print(generated_images)\n",
    "    #from (-1,1) to (0,255)\n",
    "    #generated_images=np.array(generated_images.reshape(OUTPUT*IMG_SIZE,OUTPUT*IMG_SIZE,IMG_CHANNELS), dtype=np.uint8)\n",
    "    generated_images = (generated_images+1)/2*255\n",
    "    count=0\n",
    "    for i in range(y):\n",
    "        for j in range(x):\n",
    "            if j==0:\n",
    "                array_pom=np.array(X[count].reshape(64,64,3,order='C'))\n",
    "            else:\n",
    "                array_pom=np.concatenate((array_pom,np.array(X[count].reshape(64,64,3,order='C'))),axis=1)\n",
    "            count+=1\n",
    "        if i==0:\n",
    "            array=array_pom\n",
    "        else:\n",
    "            array=np.concatenate((array,array_pom),axis=0)\n",
    "    if not os.path.exists(OUTPUT_PATH):\n",
    "        os.makedirs(OUTPUT_PATH)\n",
    "    filename = os.path.join(OUTPUT_PATH, DATA+\"-%d.png\"%(number))\n",
    "    im = Image.fromarray(((array+1)*255/2).astype(np.uint8))\n",
    "    im.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_samples(data, n_samples):\n",
    "    indexes = randint(0, data.shape[0], n_samples)\n",
    "    X = data[indexes]\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    x_input = default_rng().normal(0.0, 1.0, (n_samples, latent_dim))\n",
    "    X = generator.predict(x_input)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, generator, discriminator, dataset, latent_dim, n_samples=100):\n",
    "    #getting samples and evaluating\n",
    "    X_real, y_real = get_real_samples(dataset, n_samples)\n",
    "    _, acc_real = discriminator.evaluate(X_real, y_real, verbose=0)\n",
    "    x_fake, y_fake = generate_fake_samples(generator, latent_dim, n_samples)\n",
    "    _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
    "    AVERAGE.append([epoch,acc_real*100,acc_fake*100])\n",
    "    print('Accuracy on real: %.0f%%, on fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "    filename = DATASET_NAME+'_model_v_%.1f_e_%d.h5' % (VERSION,epoch + 1)\n",
    "    generator.save('models\\\\new\\\\'+filename,include_optimizer=True)\n",
    "    return acc_real,acc_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_ROUNDS=0\n",
    "TEMP_ROUNDS_2=0\n",
    "def check_conditions(accuracy_real,accuracy_fake):\n",
    "    #if both accuraccies is 100% for 5 epochs, than end program\n",
    "    condition_1=round(accuracy_real,2)==100.00 and round(accuracy_fake,2)==100.00\n",
    "    #Generator will be fulling discriminator with 100% accuracy for 10 epochs\n",
    "    condition_2=round(accuracy_fake,2)==100.00\n",
    "    if condition_1:\n",
    "        TEMP_ROUNDS+=1\n",
    "    else:\n",
    "        TEMP_ROUNDS=0\n",
    "    if condition_2:\n",
    "        TEMP_ROUNDS_2+=1\n",
    "    else:\n",
    "        TEMP_ROUNDS_2=0\n",
    "    if TEMP_ROUNDS==5 or TEMP_ROUNDS_2==10:\n",
    "        return False \n",
    "    return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output(avg=AVERAGE,loss=LOSS,ver=VERSION,dataset=DATASET_NAME):\n",
    "    np.savetxt(\"stat_avg_\"+dataset+\"_%d.csv\"%(ver), avg, delimiter =\", \", fmt ='% s')\n",
    "    np.savetxt(\"stat_loss_\"+dataset+\"_%d.csv\"%(ver), loss, delimiter =\", \", fmt ='% s')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, gan_model, dataset, \n",
    "          latent_dim, n_epochs=100, n_batch=10):\n",
    "    batchs_per_epoch = int(dataset.shape[0] / n_batch)\n",
    "    half_of_batch=int(int(n_batch / 2))\n",
    "    #generating fixed noise for examples images\n",
    "    fixed_noise = default_rng().normal(\n",
    "        loc=0.0, scale=1.0, size=(OUTPUT * OUTPUT, latent_dim))\n",
    "    number=1\n",
    "    i=0\n",
    "    work=True\n",
    "    while i <= n_epochs and work:\n",
    "        for j in range(batchs_per_epoch):\n",
    "            #geting and generating samples\n",
    "            X_real, y_real = get_real_samples(dataset, half_of_batch)\n",
    "            X_fake, y_fake = generate_fake_samples(\n",
    "                generator, latent_dim, half_of_batch)\n",
    "            #joining the real images with false ones\n",
    "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "            X_gan = default_rng().normal(0.0, 1.0, (n_batch,latent_dim))\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            #training\n",
    "            d_loss,_ = discriminator.train_on_batch(X, y)\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            LOSS.append([i+1,j+1,d_loss, g_loss])\n",
    "            print('Epoch:%d, Batch:%d/%d, d_loss=%.4f, g_loss=%.4f' %\n",
    "                  (i+1, j+1, batchs_per_epoch, d_loss, g_loss))\n",
    "        if (i+1) % 10 == 0:\n",
    "            #saving images based on fixed noise\n",
    "            save_images(generator, fixed_noise, number)\n",
    "            save_output()\n",
    "            number+=1\n",
    "            clear_output()\n",
    "            #getting accuracy\n",
    "            acc_real,acc_fake=summarize_performance(\n",
    "                i, generator, discriminator, dataset, latent_dim)\n",
    "            #checking the conditions to stop\n",
    "            work=check_conditions(acc_real,acc_fake)\n",
    "        i+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n",
    "discriminator = build_discriminator(image_shape)\n",
    "generator = build_generator(NOISE_SIZE, IMG_CHANNELS)\n",
    "\n",
    "gan_model = build_gan(generator, discriminator)\n",
    "#print(train_data.shape)\n",
    "train(generator, discriminator, gan_model, np.array(train_data), NOISE_SIZE,EPOCHS)\n",
    "#print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_model(filename=\"\"):\n",
    "    generator=Sequential()\n",
    "    if(filename!=\"\"):\n",
    "        generator=load_model(\"models\\\\\"+filename,compile=False)\n",
    "    return generator\n",
    "\n",
    "model = get_gen_model(\"gen_model_v_0.3_e_63.h5\")\n",
    "x=5\n",
    "y=5\n",
    "latent_points = default_rng().normal(0.0, 1.0, (x*y, NOISE_SIZE))\n",
    "image = Image.fromarray(((latent_points+1)*255/2).astype(np.uint8))\n",
    "image.show()\n",
    "X = model.predict(latent_points)\n",
    "#array = np.array(((0.5*X.reshape(64,64,3)+1)*255).astype(np.uint8))\n",
    "array=np.empty((IMG_SIZE,IMG_SIZE,IMG_CHANNELS),float)\n",
    "count=0\n",
    "for i in range(y):\n",
    "    for j in range(x):\n",
    "        if j==0:\n",
    "            array_pom=np.array(X[count].reshape(64,64,3,order='C'))\n",
    "        else:\n",
    "            array_pom=np.concatenate((array_pom,np.array(X[count].reshape(64,64,3,order='C'))),axis=1)\n",
    "        count+=1\n",
    "    if i==0:\n",
    "        array=array_pom\n",
    "    else:\n",
    "        array=np.concatenate((array,array_pom),axis=0)\n",
    "#array = np.array(((X.reshape(x*64,64,3,order='A')+1)*255/2).astype(np.uint8))\n",
    "\n",
    "image = Image.fromarray(((array+1)*255/2).astype(np.uint8))\n",
    "image.show()\n",
    "#image.save(\"output\\\\a1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93d942669e1cf03727884ffd0f90dfde4a7a65cf123d21da6912f8331dcd819b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
