{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zaimportowanie wymaganych bibliotek\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from keras.layers import Input, Reshape, Dropout, Dense, Flatten, BatchNormalization, Activation, ZeroPadding2D, LeakyReLU, Conv2DTranspose\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.losses import binary_crossentropy\n",
    "from numpy import zeros,ones,vstack\n",
    "from numpy.random import randn,randint,normal,random,choice\n",
    "from numpy.random import default_rng\n",
    "from IPython.display import clear_output\n",
    "from math import trunc\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametry\n",
    "VERSION=0.8\n",
    "\n",
    "#can be cub-cubism or del-delaunay\n",
    "DATA=\"cubism\"\n",
    "#DATA=\"delaunay\"\n",
    "\n",
    "\n",
    "#Number of saved images during training\n",
    "OUTPUT = 8 # grid of output x output images\n",
    "# For now there is no margin between images\n",
    "SAVE_FREQ = 5 #How often to save images\n",
    "OUTPUT_PATH='output\\\\new\\\\' # where to save images\n",
    "STAT_PATH=\"output\\\\statistics\\\\\" # where to save stats\n",
    "'''\n",
    "In this use case, our latent space representations are used to\n",
    "transform more complex forms of raw data (i.e. images, video),\n",
    "into simpler representations which are \"more convenient to process\" and analyze.\n",
    "'''\n",
    "NOISE_SIZE = 128#Lantent dimention size\n",
    "\n",
    "EPOCHS = 5000 #Iterations the biger, the longer the model will train\n",
    "#Batch_size=10\n",
    "BATCH_SIZE = 64 #number of images in the Batch. Larger Batch → Weak Generalization, Larger Batches → Fewer updates + shifting data → lower computational costs\n",
    "\n",
    "#AVERAGE=[[\"Epoch\",\"Accuracy on real\",\"Accuracy on fake\"]]\n",
    "STATS=[[\"Epoch\",\"batch_t\",\"d_loss\",\"g_loss\",\"acc_real\",\"acc_fake\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA ==\"delaunay\":\n",
    "    DATASET_NAME=\"del\"\n",
    "    PATH_TO_DATA='data/delaunay_data_norm.npy'\n",
    "else:\n",
    "    DATASET_NAME=\"cub\"\n",
    "    PATH_TO_DATA='data/cubism_data_norm.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(PATH_TO_DATA)\n",
    "print(\"(number of images,size_x,size_y,color_channels)\")\n",
    "print(train_data.shape)\n",
    "if train_data.shape[1]!=train_data.shape[2]:\n",
    "    print(\"Something is wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of images\n",
    "IMG_SIZE = train_data.shape[1] #rows/cols\n",
    "IMG_CHANNELS = train_data.shape[3] #color channels in our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(((train_data[1]+1)*255/2).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator\n",
    "def build_discriminator(image_shape):\n",
    "    model = Sequential(name=\"Discriminator\")\n",
    "    init = RandomNormal(mean=0.0,stddev=0.02)\n",
    "    #use bias false--> worse performance\n",
    "    model.add(Conv2D(64, kernel_size=4, strides=2, padding=\"same\",input_shape=image_shape,data_format=\"channels_last\",kernel_initializer=init))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #was 0.20\n",
    "    model.add(Dropout(0.30))    \n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\",kernel_initializer=init))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.30))    \n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=4, strides=2, padding=\"same\",kernel_initializer=init))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))    \n",
    "    model.add(Dropout(0.30))\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=4, strides=2, padding=\"same\",kernel_initializer=init))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))    \n",
    "    model.add(Dropout(0.30))\n",
    "    \n",
    "    model.add(Conv2D(1024, kernel_size=4, strides=1, padding=\"valid\",kernel_initializer=init))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))#binary clasification\n",
    "\n",
    "    opt = Adam(learning_rate=0.00002, beta_1=0.5)\n",
    "    model.compile(loss=binary_crossentropy,optimizer=opt,metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator\n",
    "#Based on UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS\n",
    "def build_generator(noise_size, channels):\n",
    "     #weight init\n",
    "     init = RandomNormal(mean=0.0,stddev=0.02)\n",
    "     model = Sequential(name=\"Generator\")\n",
    "     #todo 25 * 25 * 128\n",
    "     model.add(Dense(2 * 2 * 128, activation=\"relu\",input_dim=noise_size,kernel_initializer=init))\n",
    "     model.add(LeakyReLU(alpha=0.2))\n",
    "     # 25, 25, 128\n",
    "     model.add(Reshape((2, 2, 128)))\n",
    "     #strides 2 padding valid\n",
    "     model.add(Conv2DTranspose(1024,kernel_size=4, strides=2, padding=\"same\",kernel_initializer=init))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))    \n",
    "               \n",
    "     model.add(Conv2DTranspose(512,kernel_size=4, strides=2, padding=\"same\",kernel_initializer=init))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))    \n",
    "\n",
    "     model.add(Conv2DTranspose(256,kernel_size=4, strides=2, padding=\"same\",kernel_initializer=init))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))\n",
    "     \n",
    "     model.add(Conv2DTranspose(128,kernel_size=4, strides=2, padding=\"same\",kernel_initializer=init))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))        \n",
    "          \n",
    "     model.add(Conv2DTranspose(channels, kernel_size=4,strides=2, padding=\"same\",kernel_initializer=init))\n",
    "     model.add(Activation(\"tanh\"))    \n",
    "\n",
    "     model.summary()\n",
    "\n",
    "     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential(name=\"GAN\")\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    opt = Adam(learning_rate=0.00002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(epoch,generator, noise):\n",
    "    generated_images = generator.predict(noise)\n",
    "    array=np.empty(((IMG_SIZE,IMG_SIZE,IMG_CHANNELS)),float)\n",
    "    #from (-1,1) to (0,255)\n",
    "    #generated_images = (generated_images+1)/2*255\n",
    "    count=0\n",
    "    for i in range(OUTPUT):\n",
    "        for j in range(OUTPUT):\n",
    "            if j==0:\n",
    "                array_pom=np.array(generated_images[count].reshape(64,64,3,order='C'))\n",
    "            else:\n",
    "                array_pom=np.concatenate((array_pom,np.array(\n",
    "                    generated_images[count].reshape(64,64,3,order='C'))),axis=1)\n",
    "            count+=1\n",
    "        if i==0:\n",
    "            array=array_pom\n",
    "        else:\n",
    "            array=np.concatenate((array,array_pom),axis=0)\n",
    "    if not os.path.exists(OUTPUT_PATH):\n",
    "        os.makedirs(OUTPUT_PATH)\n",
    "    filename = os.path.join(OUTPUT_PATH, DATA+\"_v_%.1f_e_%d.png\"%(VERSION,epoch))\n",
    "    im = Image.fromarray(((array+1)*255/2).astype(np.uint8))\n",
    "    im.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_samples(data, n_samples):\n",
    "    indexes = randint(0, data.shape[0], n_samples)\n",
    "    X = data[indexes]\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    x_input = default_rng().normal(0.0, 1.0, (n_samples, latent_dim))\n",
    "    X = generator.predict(x_input)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "def smooth_positive_labels(y):\n",
    "    return y - 0.3 + (random(y.shape) * 0.5)\n",
    "\n",
    "# randomly flip some labels\n",
    "def noisy_labels(y, p_flip):\n",
    "    # determine the number of labels to flip\n",
    "    n_select = int(p_flip * y.shape[0])\n",
    "    # choose labels to flip\n",
    "    flip_ix = choice([i for i in range(y.shape[0])], size=n_select)\n",
    "    # invert the labels in place\n",
    "    y[flip_ix] = 1 - y[flip_ix]\n",
    "    return y\n",
    "\n",
    "def generate_latent_points(n_samples, latent_dim):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape((n_samples, latent_dim))\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, generator, discriminator, dataset, latent_dim, n_samples=100):\n",
    "    #getting samples and evaluating\n",
    "    X_real, y_real = get_real_samples(dataset, n_samples)\n",
    "    _, acc_real = discriminator.evaluate(X_real, y_real, verbose=0)\n",
    "    x_fake, y_fake = generate_fake_samples(generator, latent_dim, n_samples)\n",
    "    _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
    "    AVERAGE.append([epoch,acc_real*100,acc_fake*100])\n",
    "    print('Accuracy on real: %.0f%%, on fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "    filename = DATASET_NAME+'_model_v_%.1f_e_%d.h5' % (VERSION,epoch)\n",
    "    generator.save('models\\\\new\\\\'+filename,include_optimizer=True)\n",
    "    return acc_real,acc_fake\n",
    "#graf plotting\n",
    "def summarize_performance_2(epoch, generator,stats=STATS):\n",
    "    st=pd.DataFrame(stats[1:],columns=stats[0])\n",
    "    pyplot.subplot(2, 1, 1).set_title(\"Loss\")\n",
    "    pyplot.plot(st.d_loss_r, label='d-real')\n",
    "    pyplot.plot(st.d_loss_f, label='d-fake')\n",
    "    pyplot.plot(st.g_loss, label='gen')\n",
    "    pyplot.title(\"Loss\")\n",
    "    pyplot.legend()\n",
    "    pyplot.subplot(2, 1, 2).set_title(\"Accuracy\")\n",
    "    pyplot.plot(st.acc_real, label='acc-real')\n",
    "    pyplot.plot(st.acc_fake, label='acc-fake')\\\n",
    "    #todo poprawić ten tytuł\n",
    "    pyplot.title(\"Epoch: %d\"%(epoch))\n",
    "    pyplot.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    filename = DATASET_NAME+'_model_v_%.1f_e_%d.h5' % (VERSION,epoch)\n",
    "    generator.save('models\\\\new\\\\'+filename,include_optimizer=True)\n",
    "    pyplot.savefig(STAT_PATH+\"statistics_plot_v_%.1f.png\" % (VERSION))\n",
    "    st.to_csv((STAT_PATH+'stat_avg_'+DATASET_NAME+'_%.1f.csv'%(ver)))\n",
    "    #np.savetxt(STAT_PATH+'stat_avg_'+dataset+'_%.1f.csv'%(ver), avg, delimiter =',', fmt ='%s')\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It has to change here\n",
    "TEMP_ROUNDS=0\n",
    "TEMP_ROUNDS_2=0\n",
    "def check_conditions(accuracy_real,accuracy_fake):\n",
    "    #if both accuraccies is 100% for 5 epochs, than end program\n",
    "    condition_1=round(accuracy_real,2)==100.00 and round(accuracy_fake,2)==100.00\n",
    "    #Generator will be fulling discriminator with 100% accuracy for 10 epochs\n",
    "    condition_2=round(accuracy_fake,2)==100.00\n",
    "    if condition_1:\n",
    "        TEMP_ROUNDS+=1\n",
    "    else:\n",
    "        TEMP_ROUNDS=0\n",
    "    if condition_2:\n",
    "        TEMP_ROUNDS_2+=1\n",
    "    else:\n",
    "        TEMP_ROUNDS_2=0\n",
    "    if TEMP_ROUNDS==5 or TEMP_ROUNDS_2==10:\n",
    "        return False \n",
    "    return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output(avg,loss,ver=VERSION,dataset=DATASET_NAME):\n",
    "    np.savetxt(STAT_PATH+'stat_avg_'+dataset+'_%.1f.csv'%(ver), avg, delimiter =', ', fmt ='% s')\n",
    "    np.savetxt(STAT_PATH+'stat_loss_'+dataset+'_%.1f.csv'%(ver), loss, delimiter =', ', fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This model has a tendency to collapse: multiple inputs --> the same output\n",
    "def train(generator, discriminator, gan_model, dataset, \n",
    "          noise=NOISE_SIZE, n_epochs=1000, n_batch=10):\n",
    "    batchs_per_epoch = int(dataset.shape[0] / n_batch)\n",
    "    batch_size_r=int(int(n_batch / 2))\n",
    "    #generating fixed noise for examples images\n",
    "    fixed_noise = generate_latent_points(OUTPUT * OUTPUT, noise)\n",
    "    #fixed_noise = default_rng().normal(\n",
    "    #    loc=0.0, scale=1.0, size=(OUTPUT * OUTPUT, noise))\n",
    "    i=0\n",
    "    work=True\n",
    "    while i <= n_epochs and work:\n",
    "        for j in range(batchs_per_epoch):\n",
    "            #geting and generating samples\n",
    "            X_real, y_real = get_real_samples(dataset, batch_size_r)\n",
    "            X_fake, y_fake = generate_fake_samples(\n",
    "                generator, noise, n_batch-batch_size_r)\n",
    "            #joining the real images with false ones\n",
    "            #X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "            X_gan = generate_latent_points(n_batch, noise)\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            y_gan = smooth_positive_labels(y_gan)\n",
    "            #y_gan = noisy_labels(y_gan, 0.05)\n",
    "            #training\n",
    "            d_loss_r, acc_real = discriminator.train_on_batch(X_real, y_real)\n",
    "            d_loss_f, acc_fake = discriminator.train_on_batch(X_fake, y_fake)\n",
    "            #d_loss, acc_fake = discriminator.train_on_batch(X, y)\n",
    "            #_, acc_real = discriminator.evaluate(X_real, y_real, verbose=0)\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            #STATS.append([i+1,(i)*batchs_per_epoch+(j+1), d_loss_r, d_loss_f, g_loss, acc_real, acc_fake])\n",
    "            STATS.append([i+1,(i)*batchs_per_epoch+(j+1), d_loss_f,d_loss_r, g_loss, acc_real, acc_fake])\n",
    "            print('Epoch:%d, Batch:%d/%d, d_loss_r=%.4f, g_loss=%.4f' %(i+1, j+1, batchs_per_epoch, d_loss_r, g_loss))\n",
    "        if (i+1) % SAVE_FREQ == 0:\n",
    "            #saving images based on fixed noise\n",
    "            save_images(i+1,generator, fixed_noise)\n",
    "            #save_output()\n",
    "            clear_output()\n",
    "            print('Accuracy on real: %.0f%%, on fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "            #getting accuracy\n",
    "            summarize_performance_2(i+1,generator,STATS)\n",
    "            #acc_real,acc_fake=summarize_performance(i+1, generator, discriminator, dataset, noise)\n",
    "            #checking stopping conditions\n",
    "            #work=check_conditions(acc_real,acc_fake)\n",
    "            #increase the real batch part on 5\n",
    "            if batch_size_r<n_batch:\n",
    "                batch_size_r+=int(int(n_batch / 40))            \n",
    "        i+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n",
    "discriminator = build_discriminator(image_shape)\n",
    "generator = build_generator(NOISE_SIZE, IMG_CHANNELS)\n",
    "STATS=[STATS[0]]\n",
    "gan_model = build_gan(generator, discriminator)\n",
    "#print(train_data.shape)\n",
    "train(generator, discriminator, gan_model, np.array(train_data), NOISE_SIZE,EPOCHS)\n",
    "#print(train_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "col = AVERAGE[0]\n",
    "df = pd.read_csv(\"output\\\\statistics\\\\stat_avg_cub_0.7.csv\", usecols=col,sep=', ',engine='python')\n",
    "#print(\"Contents in csv file:\", df)\n",
    "plt.plot(df[[col[0]]], df[[col[1]]],color='b', label='Dyskryminator')\n",
    "plt.plot(df[[col[0]]], df[[col[2]]],color='g', label='Generator')\n",
    "plt.title(\"Accuracy during traning\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "col = LOSS[0]\n",
    "df = pd.read_csv(\"output\\\\statistics\\\\stat_loss_cub_0.7.csv\", usecols=col,sep=', ',engine='python')\n",
    "#print(\"Contents in csv file:\", df)\n",
    "plt.plot(df[[col[1]]], df[[col[2]]],color='b', label='Dyskryminator')\n",
    "plt.plot(df[[col[1]]], df[[col[3]]],color='g', label='Generator')\n",
    "plt.title(\"Loss during traning\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating image grid on already trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_model(filename=\"\"):\n",
    "    generator=Sequential()\n",
    "    if(filename!=\"\"):\n",
    "        generator=load_model(\"models\\\\\"+filename,compile=False)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_image_grid(generator, x=1, y=1):\n",
    "    latent_points = default_rng().normal(0.0, 1.0, (x*y, NOISE_SIZE))\n",
    "    X = generator.predict(latent_points)\n",
    "    array=np.empty(((IMG_SIZE,IMG_SIZE,IMG_CHANNELS)),float)\n",
    "    count=0\n",
    "    for i in range(y):\n",
    "        for j in range(x):\n",
    "            if j==0:\n",
    "                array_pom=np.array(X[count].reshape(64,64,3,order='C'))\n",
    "            else:\n",
    "                array_pom=np.concatenate((\n",
    "                    array_pom,np.array(X[count].reshape(\n",
    "                        64,64,3,order='C'))),axis=1)\n",
    "            count+=1\n",
    "        if i==0:\n",
    "            array=array_pom\n",
    "        else:\n",
    "            array=np.concatenate((array,array_pom),axis=0)\n",
    "    array=(array+1)*255/2\n",
    "    return array.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_gen_model(\"gen_model_v_0.3_e_63.h5\")\n",
    "x=8\n",
    "y=8\n",
    "array = gen_image_grid(model,x,y)\n",
    "image = Image.fromarray((array).astype(np.uint8))\n",
    "image.show()\n",
    "#image.save(\"output\\\\a1.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93d942669e1cf03727884ffd0f90dfde4a7a65cf123d21da6912f8331dcd819b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
