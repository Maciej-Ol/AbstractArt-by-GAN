{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zaimportowanie wymaganych bibliotek\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from keras.layers import Input, Reshape, Dropout, Dense, Flatten, BatchNormalization, Activation, ZeroPadding2D, LeakyReLU,Conv2DTranspose\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.metrics import Mean\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn,randint,normal\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from keras.models import load_model\n",
    "from numpy.random import randn\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA='Cubism/cubism_data_norm.npy'\n",
    "#PATH_TO_DATA='data/delaunay_data_norm.npy'\n",
    "#Parametry\n",
    "#Preview image Frame\n",
    "PREVIEW_ROWS = 4\n",
    "PREVIEW_COLS = 7\n",
    "PREVIEW_MARGIN = 4\n",
    "\n",
    "SAVE_FREQ = 100#How often to save images\n",
    "'''\n",
    "In this use case, our latent space representations are used to\n",
    "transform more complex forms of raw data (i.e. images, video),\n",
    "into simpler representations which are \"more convenient to process\" and analyze.\n",
    "'''\n",
    "NOISE_SIZE = 128#Lantent dimention size\n",
    "\n",
    "EPOCHS = 5000 #Iterations 100000\n",
    "BATCH_SIZE = 32\n",
    "GENERATE_RES = 2\n",
    "\n",
    "IMAGE_SIZE = 64 #rows/cols\n",
    "IMAGE_CHANNELS = 3#colour channels in our images\n",
    "\n",
    "cross_entropy=BinaryCrossentropy()\n",
    "mean=Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2235, 64, 64, 3)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.load(PATH_TO_DATA)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(((train_data[1]+1)*255/2).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator\n",
    "def build_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "        \n",
    "    #model.add(Conv2D(32, kernel_size=4, strides=2,input_shape=image_shape,data_format=\"channels_last\",padding=\"same\"))\n",
    "    #model.add(BatchNormalization(axis=1,momentum=0.8))\n",
    "    #model.add(LeakyReLU(alpha=0.2))\n",
    "    #model.add(Dropout(0.25))#dropout layier to prevent overfitting    \n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=4, strides=2, padding=\"same\",use_bias=False,input_shape=image_shape,data_format=\"channels_last\"))\n",
    "    #model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.20))    \n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\",use_bias=False))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.20))    \n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=4, strides=2, padding=\"same\",use_bias=False))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))    \n",
    "    model.add(Dropout(0.20))\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=4, strides=1, padding=\"same\",use_bias=False))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))    \n",
    "    model.add(Dropout(0.20))\n",
    "    \n",
    "    model.add(Conv2D(1, kernel_size=4, strides=1, padding=\"valid\",use_bias=False))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))#binary clasification\n",
    "\n",
    "    input_image = Input(shape=image_shape)\n",
    "    validity = model(input_image)\n",
    "    \n",
    "    return Model(input_image, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator\n",
    "def build_generator(noise_size, channels):\n",
    "     model = Sequential()\n",
    "     model.add(Dense(1 * 1 * noise_size, activation=\"relu\",input_dim=noise_size))\n",
    "     model.add(Reshape((1, 1, noise_size)))    \n",
    "     model.add(Conv2DTranspose(512,kernel_size=4, strides=1, padding=\"valid\", use_bias=False))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))    \n",
    "\n",
    "               \n",
    "     #model.add(UpSampling2D())\n",
    "     #model.add(Conv2D(256, kernel_size=4, padding=\"same\"))\n",
    "     model.add(Conv2DTranspose(256,kernel_size=4, strides=2, padding=\"same\", use_bias=False))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))    \n",
    "\n",
    "     #model.add(UpSampling2D())\n",
    "     #model.add(Conv2D(256, kernel_size=4, padding=\"same\"))\n",
    "     model.add(Conv2DTranspose(128,kernel_size=4, strides=2, padding=\"same\", use_bias=False))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))\n",
    "     \n",
    "     model.add(Conv2DTranspose(64,kernel_size=4, strides=2, padding=\"same\", use_bias=False))\n",
    "     model.add(BatchNormalization(momentum=0.8))\n",
    "     model.add(Activation(\"relu\"))        \n",
    "\n",
    "     #for i in range(GENERATE_RES):\n",
    "     #     model.add(UpSampling2D())\n",
    "     #     model.add(Conv2D(256, kernel_size=4, padding=\"same\"))\n",
    "     #     model.add(BatchNormalization(momentum=0.8))\n",
    "     #     model.add(Activation(\"relu\"))    \n",
    "          \n",
    "     model.add(Conv2DTranspose(channels, kernel_size=4,strides=2, padding=\"same\",use_bias=False))\n",
    "     model.add(Activation(\"tanh\"))    \n",
    "\n",
    "     model.summary()\n",
    "     \n",
    "     input = Input(shape=(noise_size,))\n",
    "     generated_image = model(input)\n",
    "\n",
    "     return Model(input, generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(cnt, noise,generator):\n",
    "    image_array = np.full((\n",
    "        PREVIEW_MARGIN + (PREVIEW_ROWS * (IMAGE_SIZE + PREVIEW_MARGIN)),\n",
    "        PREVIEW_MARGIN + (PREVIEW_COLS * (IMAGE_SIZE + PREVIEW_MARGIN)), 3),\n",
    "        255, dtype=np.uint8)\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = (generated_images+1)/2#(generated_images+1)/2   0.5*generated_images+1\n",
    "    \n",
    "    image_count = 0\n",
    "    for row in range(PREVIEW_ROWS):\n",
    "        for col in range(PREVIEW_COLS):\n",
    "            r = row * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
    "            c = col * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
    "            image_array[r:r + IMAGE_SIZE, c:c +\n",
    "                        IMAGE_SIZE] = generated_images[image_count] * 255\n",
    "            image_count += 1    \n",
    "    output_path = 'output'\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    filename = os.path.join(output_path, f\"trained-{cnt}.png\")\n",
    "    im = Image.fromarray(image_array)\n",
    "    im.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model):\n",
    "    d_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    " \n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = g_model.predict(x_input)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
    "    X_real, y_real = generate_real_samples(dataset, n_samples)\n",
    "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
    "    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
    "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "    filename = 'generator_model_%03d.h5' % (epoch + 1)\n",
    "    g_model.save('models/'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=10):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    print(dataset.shape[0])\n",
    "    half_batch = int(n_batch / 2)\n",
    "    fixed_noise = normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, NOISE_SIZE))\n",
    "    number=1\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epo):\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            print('Epoch:%d, Batch:%d/%d, d_loss=%.3f, g_loss=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
    "        if (i+1) % 10 == 0:\n",
    "            \n",
    "            save_images(number, fixed_noise,g_model)\n",
    "            number+=1\n",
    "            clear_output()\n",
    "            summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 31ms/step\n",
      ">Accuracy real: 100%, fake: 100%\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">761, 1/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      ">761, 2/69, d=0.000, g=0.375\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">761, 3/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">761, 4/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">761, 5/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      ">761, 6/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 7/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 8/69, d=0.002, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 9/69, d=0.016, g=0.003\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">761, 10/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 11/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      ">761, 12/69, d=0.000, g=0.225\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">761, 13/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">761, 14/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 15/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      ">761, 16/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 17/69, d=0.000, g=0.050\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">761, 18/69, d=0.000, g=0.021\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 19/69, d=0.000, g=0.327\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 20/69, d=0.000, g=0.237\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">761, 21/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">761, 22/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 23/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 24/69, d=0.000, g=0.190\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">761, 25/69, d=0.000, g=0.149\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      ">761, 26/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">761, 27/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">761, 28/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 29/69, d=0.000, g=0.089\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      ">761, 30/69, d=0.000, g=0.116\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 31/69, d=0.000, g=0.122\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">761, 32/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 33/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 34/69, d=0.006, g=0.000\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">761, 35/69, d=0.000, g=0.080\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 36/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 37/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">761, 38/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">761, 39/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">761, 40/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 41/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 42/69, d=0.000, g=0.002\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 43/69, d=0.001, g=0.007\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">761, 44/69, d=0.000, g=0.050\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">761, 45/69, d=0.000, g=0.109\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">761, 46/69, d=0.001, g=0.051\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 47/69, d=0.003, g=0.265\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      ">761, 48/69, d=0.005, g=0.671\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">761, 49/69, d=0.047, g=0.524\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 50/69, d=0.011, g=0.056\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      ">761, 51/69, d=0.000, g=0.837\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 52/69, d=0.003, g=0.226\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 53/69, d=0.000, g=0.063\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">761, 54/69, d=0.001, g=0.018\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 55/69, d=0.003, g=0.406\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">761, 56/69, d=0.001, g=0.010\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">761, 57/69, d=0.000, g=0.022\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">761, 58/69, d=0.001, g=0.737\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">761, 59/69, d=0.001, g=0.284\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">761, 60/69, d=0.156, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 61/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">761, 62/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 63/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      ">761, 64/69, d=0.003, g=0.000\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">761, 65/69, d=0.002, g=0.000\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      ">761, 66/69, d=0.003, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">761, 67/69, d=0.003, g=0.000\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">761, 68/69, d=0.033, g=0.016\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">761, 69/69, d=0.000, g=0.123\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">762, 1/69, d=0.000, g=0.151\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      ">762, 2/69, d=0.000, g=0.029\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">762, 3/69, d=0.017, g=0.023\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      ">762, 4/69, d=0.001, g=0.001\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">762, 5/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">762, 6/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">762, 7/69, d=0.001, g=0.090\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">762, 8/69, d=0.003, g=0.013\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      ">762, 9/69, d=0.043, g=0.124\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">762, 10/69, d=0.000, g=0.190\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">762, 11/69, d=0.001, g=0.006\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      ">762, 12/69, d=0.036, g=0.227\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      ">762, 13/69, d=0.001, g=0.192\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      ">762, 14/69, d=0.001, g=0.072\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      ">762, 15/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      ">762, 16/69, d=0.071, g=0.000\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">762, 17/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      ">762, 18/69, d=0.023, g=0.000\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      ">762, 19/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">762, 20/69, d=0.046, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">762, 21/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      ">762, 22/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">762, 23/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">762, 24/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      ">762, 25/69, d=0.000, g=0.098\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">762, 26/69, d=0.001, g=0.015\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">762, 27/69, d=0.009, g=0.000\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">762, 28/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">762, 29/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">762, 30/69, d=0.003, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">762, 31/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">762, 32/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">762, 33/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">762, 34/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">762, 35/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">762, 36/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">762, 37/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      ">762, 38/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">762, 39/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">762, 40/69, d=0.029, g=0.001\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">762, 41/69, d=0.000, g=0.031\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      ">762, 42/69, d=0.000, g=0.110\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      ">762, 43/69, d=0.000, g=0.034\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      ">762, 44/69, d=0.000, g=11.260\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">762, 45/69, d=0.001, g=0.004\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      ">762, 46/69, d=0.007, g=0.026\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">762, 47/69, d=0.001, g=0.154\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      ">762, 48/69, d=0.003, g=0.044\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">762, 49/69, d=0.001, g=0.142\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">762, 50/69, d=0.001, g=0.155\n",
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">762, 51/69, d=0.001, g=0.015\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      ">762, 52/69, d=0.003, g=0.004\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      ">762, 53/69, d=0.003, g=0.000\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">762, 54/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      ">762, 55/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      ">762, 56/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      ">762, 57/69, d=0.001, g=0.101\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      ">762, 58/69, d=0.000, g=0.975\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      ">762, 59/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">762, 60/69, d=0.000, g=0.002\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">762, 61/69, d=0.001, g=0.080\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">762, 62/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      ">762, 63/69, d=0.014, g=0.000\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">762, 64/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      ">762, 65/69, d=0.001, g=0.224\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">762, 66/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      ">762, 67/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">762, 68/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      ">762, 69/69, d=0.001, g=0.375\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      ">763, 1/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      ">763, 2/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">763, 3/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">763, 4/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">763, 5/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      ">763, 6/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      ">763, 7/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      ">763, 8/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      ">763, 9/69, d=0.018, g=0.000\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      ">763, 10/69, d=0.001, g=0.074\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">763, 11/69, d=0.001, g=0.001\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      ">763, 12/69, d=0.000, g=0.001\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">763, 13/69, d=0.000, g=0.001\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">763, 14/69, d=0.001, g=0.112\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      ">763, 15/69, d=0.001, g=0.001\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">763, 16/69, d=0.000, g=0.006\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">763, 17/69, d=0.000, g=0.011\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      ">763, 18/69, d=0.000, g=0.045\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">763, 19/69, d=0.000, g=0.132\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">763, 20/69, d=0.000, g=0.218\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">763, 21/69, d=0.000, g=0.352\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">763, 22/69, d=0.002, g=0.510\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">763, 23/69, d=0.007, g=0.216\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      ">763, 24/69, d=0.003, g=0.117\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      ">763, 25/69, d=0.003, g=0.104\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">763, 26/69, d=0.000, g=0.103\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      ">763, 27/69, d=0.006, g=0.008\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      ">763, 28/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      ">763, 29/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">763, 30/69, d=0.005, g=0.007\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">763, 31/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">763, 32/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      ">763, 33/69, d=0.000, g=0.137\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">763, 34/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">763, 35/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      ">763, 36/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      ">763, 37/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">763, 38/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      ">763, 39/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">763, 40/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">763, 41/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      ">763, 42/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">763, 43/69, d=0.001, g=0.828\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      ">763, 44/69, d=0.000, g=0.001\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">763, 45/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">763, 46/69, d=0.001, g=0.000\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      ">763, 47/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">763, 48/69, d=0.000, g=0.191\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">763, 49/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">763, 50/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      ">763, 51/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      ">763, 52/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      ">763, 53/69, d=0.024, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      ">763, 54/69, d=0.006, g=0.000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      ">763, 55/69, d=0.000, g=0.109\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      ">763, 56/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      ">763, 57/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      ">763, 58/69, d=0.000, g=0.000\n",
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [154], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m gan_model \u001b[39m=\u001b[39m define_gan(g_model, d_model)\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(train_data\u001b[39m.\u001b[39mshape)\n\u001b[1;32m----> 9\u001b[0m train(g_model, d_model, gan_model, np\u001b[39m.\u001b[39;49marray(train_data), NOISE_SIZE,EPOCHS,BATCH_SIZE)\n",
      "Cell \u001b[1;32mIn [153], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch)\u001b[0m\n\u001b[0;32m     10\u001b[0m X_fake, y_fake \u001b[39m=\u001b[39m generate_fake_samples(g_model, latent_dim, half_batch)\n\u001b[0;32m     11\u001b[0m X, y \u001b[39m=\u001b[39m vstack((X_real, X_fake)), vstack((y_real, y_fake))\n\u001b[1;32m---> 12\u001b[0m d_loss, _ \u001b[39m=\u001b[39m d_model\u001b[39m.\u001b[39;49mtrain_on_batch(X, y)\n\u001b[0;32m     13\u001b[0m X_gan \u001b[39m=\u001b[39m generate_latent_points(latent_dim, n_batch)\n\u001b[0;32m     14\u001b[0m y_gan \u001b[39m=\u001b[39m ones((n_batch, \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Old2\\.conda\\envs\\gan\\lib\\site-packages\\keras\\engine\\training.py:2144\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2140\u001b[0m   iterator \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39msingle_batch_iterator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, x,\n\u001b[0;32m   2141\u001b[0m                                                 y, sample_weight,\n\u001b[0;32m   2142\u001b[0m                                                 class_weight)\n\u001b[0;32m   2143\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_train_function()\n\u001b[1;32m-> 2144\u001b[0m   logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   2146\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2147\u001b[0m \u001b[39mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mc:\\Users\\Old2\\.conda\\envs\\gan\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Old2\\.conda\\envs\\gan\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Old2\\.conda\\envs\\gan\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Old2\\.conda\\envs\\gan\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Old2\\.conda\\envs\\gan\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Old2\\.conda\\envs\\gan\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Old2\\.conda\\envs\\gan\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_shape = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)\n",
    "d_model = build_discriminator(image_shape)\n",
    "opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "d_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])    \n",
    "\n",
    "g_model = build_generator(NOISE_SIZE, IMAGE_CHANNELS)\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "print(train_data.shape)\n",
    "train(g_model, d_model, gan_model, np.array(train_data), NOISE_SIZE,EPOCHS,BATCH_SIZE)\n",
    "#print(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "model = g_model\n",
    "latent_points = generate_latent_points(128,1)\n",
    "X = model.predict(latent_points)\n",
    "#array = np.array(((0.5*X.reshape(64,64,3)+1)*255).astype(np.uint8))\n",
    "array = np.array(((X.reshape(64,64,3)+1)*255/2).astype(np.uint8))\n",
    "\n",
    "new_image = Image.fromarray(array)\n",
    "new_image.show()\n",
    "\n",
    "#X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93d942669e1cf03727884ffd0f90dfde4a7a65cf123d21da6912f8331dcd819b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
